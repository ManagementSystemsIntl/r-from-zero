---
title: "Data Transformation and Some"
subtitle: R from Zero Training Series - Session 2
title-block-banner: "#CACACA"
format: 
  html:
    code-fold: false
    css: styles.css
    toc: true
    embed-resources: true
    smooth-scroll: true
---

```{r, echo=FALSE, include = FALSE}

library(dplyr)
library(purrr)
library(readxl)
library(sjmisc)
library(sjPlot)
library(tidyr)
library(knitr)
library(rmarkdown)
library(readr)
library(flextable)

```

# Introduction

> As a reminder, if you are working in the [repository](https://github.com/ManagementSystemsIntl/r-from-zero), please do a pull to update your workspace with items that have been pushed to the repository.

Last week, we covered the general process to review a dataset to check for common mistakes. The functions we covered were:

`filter()`: This function is used to subset rows in a dataset based on specific conditions. For example, you might want to filter out responses from participants who did not consent to the survey.

`select()`: This function allows you to subset columns in a dataset. This is useful when you want to focus on specific variables for your analysis.

`frq()`: This function is typically used to generate frequency tables for categorical variables, allowing you to see how many times each category appears in the dataset.

`map()`: This function allows you to apply a function to each element of a list or vector. It is useful for applying the same function (like `frq()`) to multiple variables in your dataset.

`tab_xtab()`: This function is used to create cross-tabulations between two categorical variables.

`table()`: This base R function creates a table of counts for categorical variables.

# Session 2: Data Transformation and Some

This week, we will continue the data analysis workflow and prepare the dataset for analysis as well as prepare a nice looking table for a report.

In this session, we will cover:

-   Overview of mistakes found in the raw data

-   Functions to correct those mistakes

-   Functions for summary statistics

-   Creating report-ready tables

# Recap on the Messy Data

From the previous session, we focused on finding all the different type of errors in a dataset. Generally, if you are receiving a "messy" dataset it is during the pilot or testing phase and you will have an opportunity to correct these scripting mistakes which caused these errors. However, in some cases, not all errors will be caught and there is a need to clean the data before analysis.

First, installed packages, load libraries and create an object of the dataset. Also, we should only work with those who consented to be interview, so let's filter the rest out.

```{r, warning=FALSE}
# Install required packages
install.packages(c("dplyr", "purrr", "readxl", "sjmisc", "sjPlot", "readr", "flextable"))

# Load libraries
library(dplyr)
library(purrr)
library(readxl)
library(sjmisc)
library(sjPlot)
library(readr)
library(flextable)

# Create an object for the dataset
raw <- read.csv("C:/Users/melanie.murphy/Desktop/R projects/r-from-zero/week 2/data/raw/week 2 dataset.csv")

# Filter to keep those who consented to be interviewed 
raw <- raw %>% 
  filter(consent=="Yes")

```

# Let's Get You Cleaned!

> It is important to note, we should never change raw data. There should be a record of what the raw exported data was. When we make changes to the data we save the data as a cleaned dataset. When you are working on an advanced analysis process, there would be another layer of data preparation (remember the 02 prepared file I mentioned last time?). But in this case, we can assume we are working with TPM data so we may just need a clean script before we jump into the analysis.

Let's run through a few important functions that are commonly used for data transformation.

## Using `mutate()`

This function is very versatile and can be used with a wide range of functions and commands to perform various types of data transformations. It is used to add new variables or transform existing ones within a data frame.

There are many types of functions you might use with `mutate()`but the key ones we will focus on are conditional statements.

### Using `ifelse()`

This function returns a value based on whether a condition is true or false. 

```{r}
frq(raw$education)
# ERROR: Incorrect label, "None" 

raw <- raw %>% 
  mutate(education = ifelse(education=="None","No formal education", education))

frq(raw$education)
```

There are several questions that have missing values since if respondents didn't receive assistance, they weren't asked these questions. Below we set the missing values to `NA_real_` for `R` to register they are true missing values. 

```{r}
frq(raw$satisfaction)

raw <- raw %>% 
  mutate(satisfaction = ifelse(satisfaction=="", NA_real_, satisfaction),
         dissatisfied_reason = ifelse(dissatisfied_reason=="", NA_real_, dissatisfied_reason),
         quantity = ifelse(quantity=="", NA_real_, quantity),
         quality = ifelse(quality=="", NA_real_, quality))

frq(raw$satisfaction)
```
### Using `case_when()`

This function creates new variables based on a series of conditional statements. 

> The ~ symbol is used in the case_when() function in R to separate the condition from the result. It is part of the syntax for defining a series of conditional statements. Each condition and its corresponding result are defined using the syntax condition ~ result, and multiple conditions can be chained together within the case_when() function.

```{r}
frq(raw$city) 
# ERROR: Misspelling of City Xai-Xai

raw <- raw %>% 
  mutate(city = case_when(city=="XaiXai" ~ "Xai-Xai",
                          TRUE ~ city))
frq(raw$city) 
```

Another example from the survey data. 

```{r}
frq(raw$registered) 
# ERROR: registered has some responses coded and some not

raw <- raw %>% 
  mutate(registered = case_when(registered==1 ~ "Yes",
                                registered==0 ~ "No", 
                                TRUE ~ registered))

frq(raw$registered) 
```

::::: box
::: box-header
Other uses for `mutate()`
:::

::: box-container

**Arithmetic operation:** You can use arithmetic operations to create new variables or modify existing ones.

```{r}
# Example data frame
df <- data.frame(id = 1:10,
                 value = rnorm(10))

# Create a new variable that is double the value
df <- df %>%
  mutate(double_value = value * 2)
df
```

**Mathematical functions:** You can use mathematical functions such as `log()`, `sqrt()`, `exp()`, etc.

```{r, warning=FALSE}
# Create a new variable that is the square root of the value
df <- df %>%
  mutate(sqrt_value = sqrt(value))
df
```

**Aggregated values:** You can use aggregated values with functions like `mean()`, `sum(),` `min()`, `max()`, etc.

```{r}
# Create a new variable that is the mean value within each group
df <- df %>%
  mutate(mean_value = mean(value))
df
```

**Date and time functions:** You can use date and time functions such as `as.Date()`, `as.POSIXct()`, etc.

```{r}
# Create a new variable that extracts the year from the date
df <- df %>%
  mutate(date = as.Date('2025-01-01') + 0:9,
         year = format(date, "%Y"))
df
```

:::
:::::

## Using `rename()`

This function allows you to rename columns in a data frame. It is especially useful for improving the readability of your data by giving columns more descriptive names. The syntax for `rename()` is `rename(new_name = old_name)`, where `new_name` is the new name for the column and `old_name` is the current name of the column.

```{r}
raw <- raw %>%
  rename(dis_reason = dissatisfied_reason)
head(raw)
```

## Save Cleaned Data
Now that the data is cleaned, let's save it and start using the clean data object. 

```{r}
# Save cleaned data ----
write_csv(raw, "C:/Users/melanie.murphy/Desktop/R projects/r-from-zero/week 2/data/cleaned/week 2 dataset cleaned.csv")
write_rds(raw, "C:/Users/melanie.murphy/Desktop/R projects/r-from-zero/week 2/data/cleaned/week 2 dataset cleaned.rds")

# Create an object for the dataset
cln <- readRDS("C:/Users/melanie.murphy/Desktop/R projects/r-from-zero/week 2/data/cleaned/week 2 dataset cleaned.rds")
```

# Let's Analyze!

We made it. We have a nice and tidy dataset ready to use for analyzing the data. Let's run through a few steps commonly used in the data analysis process. 

## Using `summarize()`

This function manipulates observations based on the value of one or more variables. It is often used to calculate summary statistics such as means, counts, or proportions. Note, `na.rm = TRUE` means you want to exclude the NAs when it calculates the mean.

```{r}
age_mn <- cln %>% 
  summarize(mean_age = mean(age, na.rm = TRUE))

age_mn
```

## Using `groupby()`

This function groups the data by one or more variables. It is often used in conjunction with `summarize()` to calculate summary statistics for each group.

```{r}
age_city_mn <- cln %>% 
  group_by(city) %>% 
  summarize(mean_age = mean(age, na.rm = TRUE))

age_city_mn
```

Let's add more to this table by adding `n()` to add the number of observations in each city. 

```{r}
age_city_mn_count <- cln %>% 
  group_by(city) %>% 
  summarize(mean_age = mean(age, na.rm = TRUE),
            N = n()) 

age_city_mn_count
```
## Using `arrange()`

This function reorders the rows of a data frame based on the values of one or more variables. You can sort in ascending or descending order using the `desc()` function.

```{r}
age_city_mn_count_desc <- cln %>% 
  group_by(city) %>% 
  summarize(mean_age = mean(age, na.rm = TRUE),
            N = n()) %>% 
  arrange(desc(mean_age))

age_city_mn_count_desc
```

# Creating a Flextable

The process we just went through was to create a table-ready object. Now that we know the steps to take, we can go a step further and use the `flextable()` function to make the output report-ready. 

Let's create an object for a different variable than the one used above. First, we need to create a new numeric variable from one of the survey questions. 

```{r}
cln <- cln %>% 
  mutate(reg_bin = ifelse(registered=="Yes", 1, 0))

frq(cln$reg_bin)
```

Now, we can create the object.

```{r}
reg_city_mn_desc <- cln %>% 
  group_by(city) %>% 
  summarize(mean_reg = mean(reg_bin, na.rm = TRUE),
            N = n()) %>% 
  arrange(desc(mean_reg))

reg_city_mn_desc
```
Now, let's use this object to create a flextable.

```{r}
reg_city_mn_desc_flx <- reg_city_mn_desc %>% 
  flextable()
reg_city_mn_desc_flx
```

The presentation can definitely be improved. Let's reorder the table, rename the headers and fix the mean to be in a percent format. 

```{r}
reg_city_mn_desc_flx <- reg_city_mn_desc %>% 
  select("City"=city, "Number"=N, "Percent"=mean_reg) %>% 
  flextable() %>% 
  set_formatter(Percent=function(x) sprintf("%.1f%%", x*100))
reg_city_mn_desc_flx
```
Now, let's add a caption and autofit the table. 

```{r}
reg_city_mn_desc_flx <- reg_city_mn_desc %>% 
  select("City"=city, "Number"=N, "Percent"=mean_reg) %>% 
  flextable() %>% 
  set_formatter(Percent=function(x) sprintf("%.1f%%", x*100)) %>%
  add_footer_lines(values="Q8. Are you the registered beneficiary for this distribution?") %>% 
  set_table_properties(layout="autofit")
  
reg_city_mn_desc_flx

# Save the flextable
save_as_docx("Q8. Registered Beneficiary"=reg_city_mn_desc_flx, 
             path=("C:/Users/melanie.murphy/Desktop/R projects/r-from-zero/week 2/output/tables/q8. registered beneficiary.docx"))
```

# Breakout Session

There are two goals of the breakout sessions. First, to offer any support on material we have covered so far. Second, is to create a flextable of one of the survey questions. 

Participants will be broken out into working groups to follow the steps conducted under the "Creating a Flextable" section above. 

-   Choose one of these questions to analyze: consent, registered, received_assistance, satisfaction, quantity or quality. 
-   Create a new numeric variable in binary form (0,1) from the question selected, using `mutate()`.
-   Choose one of these demographic variables to `groupby()`: city, sex, education, employment. Bonus if you create a categorical variable from age and use that. 
-   Create a table-ready object using the question and disaggregation of choice. 
-   Create a `flextable()` that includes the number and percent of responses. 

